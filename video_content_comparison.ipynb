{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma3rNiz3YkCM"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y9J4RXFqkcW"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import random\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import parafac\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXbQin8kqQab",
    "outputId": "51ffc9c0-5482-4ffd-91a5-0791fdbd6681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE1 1000\n",
      "SAMPLE2 1000\n"
     ]
    }
   ],
   "source": [
    "#import cupy as cp\n",
    "def count_frames_manual(video):\n",
    "    total = 0\n",
    "    while True:\n",
    "        (grabbed, frame) = video.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "        total += 1\n",
    "\n",
    "    return total\n",
    "\n",
    "sample1 = cv2.VideoCapture('/content/Ch3_20211025102801_2.mp4')\n",
    "sample2 = cv2.VideoCapture('/content/Ch3_20211025174706_2.mp4')\n",
    "#sample3 = cv2.VideoCapture('/content/Ch3_20211025195110_2.mp4')\n",
    "#sample4 = cv2.VideoCapture('/content/Ch3_20211025113444_2.mp4')\n",
    "#test_sample = cv2.VideoCapture('/content/material3.mp4')\n",
    "grey_sample = cv2.VideoCapture('/content/material4.mp4')\n",
    "sample1_frames = int(sample1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"SAMPLE1 \" + str(sample1_frames))\n",
    "sample2_frames = int(sample2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"SAMPLE2 \" + str(sample2_frames))\n",
    "#sample3_frames = int(sample3.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#sample4_frames = int(sample4.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#test_frames = int(test_sample.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#print(\"TEST SAMPLE:\" + str(test_frames))\n",
    "grey_frames = int(grey_sample.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "def read_frames(video_capture, max_frames):\n",
    "    frames_array = []\n",
    "    frame_nb = 0\n",
    "    \n",
    "    while video_capture.isOpened() and frame_nb < max_frames:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        frames_array.append(frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        frame_nb += 1\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames_array\n",
    "\n",
    "#x_gpu = cp.ones((100,100,100))\n",
    "sample_1_array = read_frames(video_capture = sample1, max_frames = sample1_frames)\n",
    "sample_2_array = read_frames(video_capture = sample2, max_frames = sample2_frames)\n",
    "test_sample_array = read_frames(video_capture = test_sample , max_frames = test_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "MlenZZVEwHxl",
    "outputId": "b21acb5d-7d6b-44ac-f570-16e4441ca7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time diff = 0:00:10.034805\n",
      "time diff 2 = 0:00:07.704277\n",
      "[8, 36, 4, 16, 7, 31, 28, 30, 41, 24]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nprint(Euclidean_distance_1) \\n#print(Euclidean_distance_2) \\n#print(Euclidean_distance_3)\\n#print(Euclidean_distance_4)\\n#print(Euclidean_distance_5)\\n#print(factors_subset_sample1)\\n#print(factors_subset_sample2)\\n\\nwith open('output_1.txt', 'a') as f1:\\n    print(factors_subset_sample1, file=f1)\\n\\n\\nwith open('output_2.txt', 'a') as f2:\\n    print(factors_subset_sample2, file=f2)\\n#print(factors_subset_sample3)\\n#print(factors_subset_sample4)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker, parafac\n",
    "from IPython import display\n",
    "#import cupy as cp\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "def count_frames_manual(video):\n",
    "    total = 0\n",
    "    while True:\n",
    "        (grabbed, frame) = video.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "        total += 1\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "sample1 = cv2.VideoCapture('/content/Ch3_20211025102801_2.mp4')\n",
    "sample2 = cv2.VideoCapture('/content/Ch3_20211025174706_2.mp4')\n",
    "\n",
    "sample3 = cv2.VideoCapture('/content/Ch3_20211025195110_2.mp4')\n",
    "sample4 = cv2.VideoCapture('/content/Ch3_20211025113444_2.mp4')\n",
    "#test_sample = cv2.VideoCapture('/content/material3.mp4')\n",
    "sample1_frames = int(sample1.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "sample2_frames = int(sample2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"SAMPLE1 \" + str(sample1_frames))\n",
    "#print(\"SAMPLE2 \" + str(sample2_frames))\n",
    "\n",
    "sample3_frames = int(sample3.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"SAMPLE3 \" + str(sample3_frames))\n",
    "sample4_frames = int(sample4.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"SAMPLE4 \" + str(sample4_frames))\n",
    "\n",
    "test_frames = int(test_sample.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"TEST SAMPLE:\" + str(test_frames))\n",
    "\n",
    "print(\"TEST SAMPLE:\" + str(test_frames))\n",
    "\n",
    "def read_frames(video_capture, max_frames, batch_size, stop_size):\n",
    "    batch_list = []\n",
    "    frame_nb = 0\n",
    "\n",
    "    for batch_id in range(0, math.ceil(max_frames / batch_size)):\n",
    "        frames_array = []\n",
    "\n",
    "        #print(batch_id)\n",
    "        #print(video_capture.isOpened())\n",
    "        flag = 1\n",
    "        # within the array, the frame_nb should be 0-99, 100-199, 200-299 ....\n",
    "        while video_capture.isOpened() and frame_nb <= batch_size * (batch_id + 1) and flag <= batch_size:\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames_array.append(frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            frame_nb += 1\n",
    "            if frame_nb == batch_size * (batch_id + 1):\n",
    "                break\n",
    "            flag += 1\n",
    "\n",
    "        # print(frames_array)\n",
    "        batch_list.append(frames_array)\n",
    "        batch_id += 1\n",
    "        if batch_id == stop_size:\n",
    "            break;\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return batch_list\n",
    "\n",
    "\n",
    "a_100 = datetime.datetime.now()\n",
    "sample_1_array = read_frames(video_capture = sample1, max_frames = sample1_frames, batch_size=100, stop_size=10)\n",
    "b_100 = datetime.datetime.now()\n",
    "print(\"time diff = \" + str(b_100 - a_100))\n",
    "\n",
    "sample_gray_array = read_frames(video_capture = grey_sample, max_frames = grey_frames, batch_size=50, stop_size=20)\n",
    "                                                                                                                                 \n",
    "a_50 = datetime.datetime.now()\n",
    "sample_1_array_50 = read_frames(video_capture = sample1, max_frames = sample1_frames, batch_size=50, stop_size=20)\n",
    "b_50 = datetime.datetime.now()\n",
    "print(\"time diff = \" + str(b_50 - a_50))\n",
    "\n",
    "a_30 = datetime.datetime.now()\n",
    "sample_1_array_30 = read_frames(video_capture = sample1, max_frames = sample1_frames, batch_size=33, stop_size=30)\n",
    "b_30 = datetime.datetime.now()\n",
    "print(\"time diff = \" + str(b_30 - a_30))\n",
    "\n",
    "\n",
    "test_sample_array = read_frames(video_capture = test_sample, max_frames = test_frames, batch_size=100, stop_size=10)\n",
    "a_100_2 = datetime.datetime.now()\n",
    "sample_2_array = read_frames(video_capture = sample2, max_frames = sample2_frames, batch_size=30, stop_size=33)\n",
    "b_100_2 = datetime.datetime.now()\n",
    "print(\"time diff 2 = \" + str(b_100_2 - a_100_2))\n",
    "\n",
    "\n",
    "a_50_2 = datetime.datetime.now()\n",
    "sample_2_array_50 = read_frames(video_capture = sample2, max_frames = sample2_frames, batch_size=50, stop_size=20)\n",
    "b_50_2 = datetime.datetime.now()\n",
    "print(\"time diff 2 = \" + str(b_50_2 - a_50_2))\n",
    "\n",
    "\n",
    "a_30_2 = datetime.datetime.now()\n",
    "sample_2_array_30 = read_frames(video_capture = sample2, max_frames = sample2_frames, batch_size=33, stop_size=30)\n",
    "b_30_2 = datetime.datetime.now()\n",
    "print(\"time diff 2 = \" + str(b_30_2 - a_30_2))\n",
    "\n",
    "a_100_3 = datetime.datetime.now()\n",
    "sample_3_array = read_frames(video_capture = sample3, max_frames = sample3_frames, batch_size=100, stop_size=10)\n",
    "b_100_3 = datetime.datetime.now()\n",
    "print(\"time diff 3 = \" + str(b_100_3 - a_100_3))\n",
    "\n",
    "a_50_3 = datetime.datetime.now()\n",
    "sample_3_array = read_frames(video_capture = sample3, max_frames = sample3_frames, batch_size=50, stop_size=20)\n",
    "b_50_3 = datetime.datetime.now()\n",
    "print(\"time diff 3 = \" + str(b_50_3 - a_50_3))\n",
    "\n",
    "a_30_3 = datetime.datetime.now()\n",
    "sample_3_array = read_frames(video_capture = sample3, max_frames = sample3_frames, batch_size=33, stop_size=30)\n",
    "b_30_3 = datetime.datetime.now()\n",
    "print(\"time diff 3 = \" + str(b_30_3 - a_30_3))\n",
    "\n",
    "a_100_4 = datetime.datetime.now()\n",
    "sample_4_array = read_frames(video_capture = sample4, max_frames = sample4_frames, batch_size=100, stop_size=10) \n",
    "b_100_4 = datetime.datetime.now()\n",
    "print(\"time diff 4 = \" + str(b_100_4 - a_100_4))\n",
    "\n",
    "a_50_4 = datetime.datetime.now()\n",
    "sample_4_array = read_frames(video_capture = sample4, max_frames = sample4_frames, batch_size=50, stop_size=20) \n",
    "b_50_4 = datetime.datetime.now()\n",
    "print(\"time diff 4 = \" + str(b_50_4 - a_50_4))\n",
    "\n",
    "a_30_4 = datetime.datetime.now()\n",
    "sample_4_array = read_frames(video_capture = sample4, max_frames = sample4_frames, batch_size=33, stop_size=30) \n",
    "b_30_4 = datetime.datetime.now()\n",
    "print(\"time diff 4 = \" + str(b_30_4 - a_30_4))\n",
    "\n",
    "print(len(test_sample_array))\n",
    "\n",
    "grey_tensor = tl.tensor(np.array(sample_gray_array))\n",
    "\n",
    "#tensor_test = tl.tensor(np.array(test_sample_array[0]))\n",
    "tensor_1 = tl.tensor(np.array(sample_1_array[0]))\n",
    "tensor_2 = tl.tensor(np.array(sample_2_array[0]))\n",
    "\n",
    "\n",
    "'''\n",
    "count_dynamic = 0\n",
    "count_dy = []\n",
    "count_static = 0\n",
    "count_sta = []\n",
    "\n",
    "\n",
    "for i in range(len(sample_1_array[0])):\n",
    "    for j in range(len(sample_1_array[0][i])):\n",
    "        for k in range(len(sample_1_array[0][i][j])):\n",
    "            sparsity_array_val = sample_1_array[0][i][j][k]\n",
    "            #print(sparsity_array_val)\n",
    "            if(sparsity_array_val[0] > 10):\n",
    "                count_dynamic += 1\n",
    "            else:\n",
    "                count_static += 1\n",
    "\n",
    "\n",
    "print(count_dynamic)\n",
    "print(count_static)\n",
    "'''\n",
    "\n",
    "tensor_3 = tl.tensor(np.array(sample_3_array[0]))\n",
    "tensor_4 = tl.tensor(np.array(sample_4_array[0]))\n",
    "\n",
    "\n",
    "random.seed(1)\n",
    "random_frames = random.sample(range(0, 50), 10)\n",
    "print(random_frames)\n",
    "\n",
    "fixed_frames = range(0,16)\n",
    "\n",
    "subset_sample1_cp = tensor_1[fixed_frames,: ,: ,:].astype('d')\n",
    "subset_sample2_cp = tensor_2[fixed_frames,: ,: ,:].astype('d')\n",
    "\n",
    "subset_sample_test = tensor_test[random_frames,: ,: ,:].astype('d')\n",
    "\n",
    "subset_sample1 = tensor_1[random_frames,: ,: ,:].astype('d')\n",
    "subset_sample2 = tensor_2[random_frames,: ,: ,:].astype('d')\n",
    "\n",
    "\n",
    "subset_sample3 = tensor_3[random_frames,: ,: ,:].astype('d')\n",
    "subset_sample4 = tensor_4[random_frames,: ,: ,:].astype('d')\n",
    "\n",
    "\n",
    "core_subset_test, factors_subset_test = tucker(subset_sample_test, rank = [1,1,1,1])\n",
    "core_subset_sample1, factors_subset_sample1 = tucker(subset_sample1, rank = [1,1,1,1])\n",
    "core_subset_sample2, factors_subset_sample2 = tucker(subset_sample2, rank = [1,1,1,1])\n",
    "\n",
    "core_subset_sample1_4 = tucker(subset_sample1, rank = [2,2,2,2])\n",
    "\n",
    "\n",
    "core_subset_sample3, factors_subset_sample3 = tucker(subset_sample3, rank = [1,1,1,1])\n",
    "core_subset_sample4, factors_subset_sample4 = tucker(subset_sample4, rank = [1,1,1,1])\n",
    "\n",
    "\n",
    "Euclidean_distance_1 = np.linalg.norm(core_subset_sample1 - core_subset_sample2)\n",
    "Euclidean_distance_2 = np.linalg.norm(core_subset_sample1 - core_subset_sample3)\n",
    "\n",
    "Euclidean_distance_3 = np.linalg.norm(core_subset_sample2 - core_subset_sample3)\n",
    "Euclidean_distance_4 = np.linalg.norm(core_subset_sample1 - core_subset_sample4)\n",
    "Euclidean_distance_5 = np.linalg.norm(core_subset_sample2 - core_subset_test)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "print(Euclidean_distance_1) \n",
    "print(Euclidean_distance_2) \n",
    "print(Euclidean_distance_3)\n",
    "print(Euclidean_distance_4)\n",
    "print(Euclidean_distance_5)\n",
    "print(factors_subset_sample1)\n",
    "print(factors_subset_sample2)\n",
    "\n",
    "with open('output_1.txt', 'a') as f1:\n",
    "    print(factors_subset_sample1, file=f1)\n",
    "\n",
    "\n",
    "with open('output_2.txt', 'a') as f2:\n",
    "    print(factors_subset_sample2, file=f2)\n",
    "print(factors_subset_sample3)\n",
    "print(factors_subset_sample4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_qLo3sRleqo",
    "outputId": "8a5bd6b1-e60c-485e-8a06-96b2245da4c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(subset_sample1_cp.shape)\n",
    "print(subset_sample1_cp[0].shape)\n",
    "original_single_channel = subset_sample1_cp[2:3: ,: ,: ,0:1]\n",
    "original_single_channel.shape\n",
    "\n",
    "print(np.array(original_single_channel)[0][:][:].shape)\n",
    "original_init = original_single_channel[0][:][:]\n",
    "original_cut = original_single_channel[0][:][:].reshape(1080,1920)\n",
    "#the step is to cut from SVD and do recovery \n",
    "original_cut.shape\n",
    "\n",
    "grey_tensor.shape\n",
    "#subset_grey_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEeMo1OkqZYW"
   },
   "outputs": [],
   "source": [
    "#cp decomposition for foreground and background\n",
    "#separate into low-rank tensor and sparse-tensor\n",
    "core_subset_sample1_cp = parafac(subset_sample1_cp, rank=3 ,n_iter_max=50, tol = 1.0e-5, linesearch=False)\n",
    "core_subset_sample2_cp = parafac(subset_sample2_cp, rank=3 ,n_iter_max=50, tol = 1.0e-5, linesearch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BinHQR9fwSzu"
   },
   "outputs": [],
   "source": [
    "#algorithm goes here \n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "sufrom timeit import timeit\n",
    "from optimizers import gradient_descent\n",
    "from plotters import convergence_plot, kwargs, setup_layout\n",
    "\n",
    "def nuclear_norm(A):\n",
    "    U,sigma,VofT = np.linalg.svd(A)\n",
    "    return U,sigma,VofT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9PDHW4xpOru"
   },
   "outputs": [],
   "source": [
    "#@ RPCA for decomposition M = L0 + S0\n",
    "#the nuclear norm in numpy: numpy.linalg.norm\n",
    "#the L1 norm in numpy \n",
    "#the L0 norm in numpy \n",
    "#the SVD in tensorflow is memory so the SVD function need to be rewrote \n",
    "#L0 could be calculated by SVD where L0 = UDV^T\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def reshape_ori(m):\n",
    "    shape_ori = m.shape\n",
    "    m1 = m.reshape(shape_ori[0]*shape_ori[1], shape_ori[2])\n",
    "    m2 = m.reshape(shape_ori[0], shape_ori[1]*shape_ori[2])\n",
    "    m3 = m.reshape(shape_ori[2], shape_ori[0]*shape_ori[1])\n",
    "    return m1, m2, m3 \n",
    "\n",
    "# the shape of M must be n1 * n2\n",
    "def rpca(M, thre):\n",
    "    # the shape of m is shape_ori\n",
    "    shape_0 = M.shape\n",
    "    shape1 = shape_0[0] #1920\n",
    "    shape2 = shape_0[1] #1080\n",
    "    shape3 = shape_0[2] #3\n",
    "\n",
    "    # Low-rank matrix\n",
    "    L = np.zeros(shape_0)\n",
    "    # Sparse matrix \n",
    "    S = np.zeros(shape_0)\n",
    "    # Lagrange multiplier matrix \n",
    "    Y = np.zeros(shape_0)\n",
    "\n",
    "    # initialization with Lamda(1/squa(n1) where  n_1=max(n1,n2), n_2=min(n1,n2)), Mu, Delta\n",
    "    # the following steps are converting M to L,S \n",
    "    # the probability of reconstructing M which is 1− CN^(−10)\n",
    "    n_1 = np.max(shape1, shape2)\n",
    "    n_2 = np.min(shape1, shape2)\n",
    "    lam = 1/np.sqrt(n_1)\n",
    "    mu = (shape1*shape2)/(4 * np.linalg.norm(M,ord=1,keepdims=True))\n",
    "    # iteration number \n",
    "    k=0\n",
    "\n",
    "    # when this is satisfied,  iterationthe could stop \n",
    "    terminate_flag = np.linalg.norm(M-L-S,ord='fro',keepdims=True) <= 10^(-7) * np.linalg.norm(M,ord='fro',keepdims=True)\n",
    "\n",
    "    # the stop critieria need to be considered \n",
    "    while terminate_flag: #condition required \n",
    "      L = singular_threshold(M - S + (1/mu) * Y, 1/mu)\n",
    "      S = soft_threshold(M - L + (1/mu) * Y, lam * (1/mu))\n",
    "      Y = Y + mu * (M - L - S)\n",
    "    \n",
    "    L = L.reshape(shape1, shape2, shape3)\n",
    "    S = S.reshape(shape1, shape2, shape3)\n",
    "\n",
    "    return L, S\n",
    "\n",
    "# this method is to calculate the mid component of SVD result \n",
    "def soft_threshold(x, t):\n",
    "    para1 = np.sign(x)\n",
    "    para2 = np.maximum((np.fabs(x)-t), 0)\n",
    "    return np.multiply(para1, para2)\n",
    "\n",
    "def singular_threshold(x, t):\n",
    "    u, d, v = np.linag.svd(x)\n",
    "    res = u * soft_threshold(d, t) * np.transpose(v)\n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNFaWriTtrxO"
   },
   "outputs": [],
   "source": [
    "##visualization with convert into array and convert back to image \n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "image_data = np.asarray(grey_tensor)\n",
    "# convert the single channel data into RGB value which could be expressed as color information\n",
    "image_data2 = Image.fromarray((grey_tensor * 255).astype(np.uint8))\n",
    "image_data3 = Image.fromarray((core_subset_sample1*255).astype(np.uint8))\n",
    "image_data2.save('/content/try2.png')\n",
    "image_data3.save('/content/try3.png')\n",
    "#print(core_subset_sample2_cp.weights)\n",
    "#print(core_subset_sample2_cp.factors)\n",
    "img_data_factors = np.asarray(core_subset_sample2_cp.factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDtoJbzyrOCN"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "video content comparison",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
